> 1、ChatGPT有安全机制
> 
> 2、ChatGPT能够理解上下文，大约能记住8000词（GPT-4现在达到了25000词）
> 
> 3、ChatGPT能够理解自己的局限性

ChatGPT用到的是和InstructGPT一样的技术，
InstructGPT的输入是prompt的形式，ChatGPT是对话形式，
区别是InstructGPT是在GPT3上微调，ChatGPT是在GPT3.5上微调。
GPT3.5是GPT3的数据＋Codex的数据 然后再在InstructGPT上用一些人类标注的数据做微调。

## InstructGPT
Training language models to follow instructions with human feedback

通过zero-shot做的大模型的控制能力太弱了，会有两个问题：
> 1、有效性，想让模型去学做一件事，但是模型就是学不会，因为你的文本中可能就没有相关的东西。
>
> 2、安全性，你的模型输出一些不应该输出的内容。
> 
如果我们去标注一点数据，再对语言模型进行微调，效果会更好一些，能够更加服从人类的指示，也就是InstructGPT的含义。
**fine-tuning with human feedback**

**RLHF，基于人类反馈的强化学习** 收集很多问题，使用标注工具将问题的答案写出来，用这些数据集对GPT3进行微调。接下来再收集一个数据集，通过刚才微调的模型输入问题得到一些输出答案，人工对这些答案按好坏进行排序，然后通过强化学习继续训练微调后的模型，这个模型就叫InstructGPT。

结果上说，有了标注的数据集，1.3B的模型参数的InstructGPT要好过最大的175B参数的GPT3。说明适当加入一些人工的标注数据，可能总的成本会降低。

### 两个标注数据集，三个模型。

1、找人来写出各种各样的问题（或者从GPT3接口收集的问题），这些问题在GPT里面叫做prompt

例如：什么是月亮？

2、让人根据问题写答案

例如：围绕地球旋转的球形天体。

3、将问题和答案拼在一起，形成一段对话。大量这样的对话文本，形成第一个标注数据集。

例如：什么是月亮？围绕地球旋转的球形天体。

4、使用这些对话微调GPT3。GPT3的模型在人类标注的这些数据上进行微调出来的模型叫做SFT(supervised fine-tune)，有监督的微调。这就是训练出来的第一个模型。

5、给出一个问题，通过SFT模型生成几个答案，这里假设生成四个答案。

例如：什么是月亮？

SFT模型生成了四个答案：

A、月亮是太阳系中离地球最近的天体。

B、月亮是太阳系中体积第五大的卫星。

C、月亮是由冰岩组成的天体，在地球的椭圆轨道上运行。

D、月亮是地球的卫星。

6、将四个答案让人根据好坏程度进行排序。

例如：张三觉得答案D是最好的，其次是C，C比A要好，A和B差不多。就是D>C>B=A。

7、将大量的人工排序整理为一个数据集，就是第二个标注数据集。

8、使用排序数据集训练一个RM模型，reward model，奖励模型。这是第二个模型。

模型输入：问题+答案，例如：什么是月亮？月亮是地球的卫星。

模型输出：分数，例如：9.4。

优化目标：问题+答案得到的分数要满足人工排序的顺序。

例如：

什么是月亮？月亮是太阳系中离地球最近的天体。	5.4

什么是月亮？月亮是太阳系中体积第五大的卫星。	5.4

什么是月亮？月亮是由冰岩组成的天体，在地球的椭圆轨道上运行。	8.2

什么是月亮？月亮是地球的卫星。 	9.4

这里得到的分数就满足张三的排序：D>C>B=A。

9、继续给出一些没有答案的问题，通过强化学习继续训练SFT模型，新的模型叫做RLHF模型。优化目标是使得SFT模型根据这些问题得到的答案在RM模型中得到的分数越高越好。这是第三个模型。

10、最终微调后的RLHF模型就是InstructGPT模型。

备注：两次对模型的微调：GPT3模型—>SFT模型—>RLHF模型，其实这里始终都是同一个模型，只是不同过程中名称不一样。

需要SFT模型的原因：GPT3模型不一定能够保证根据人的指示、有帮助的、安全的生成答案，需要人工标注数据进行微调。

需要RM模型的原因：标注排序的判别式标注，成本远远低于生成答案的生成式标注。

需要RLHF模型的原因：在对SFT模型进行微调时，生成的答案分布也会发生变化，会导致RM模型的评分会有偏差，需要用到强化学习。

#### InstructGPT的结果：

1. 比GPT3的结果要好很多

2. 在真实性上比GPT3好一些

3. 在生成有问题的结果上比GPT3好一些，但在偏见上并没有太多的提升。

4. 微调都是在某个任务上做微调，可能会在一些别的任务上性能会下降。

5. 标注非常有主观性，不过人类之间的喜好虽然不完全一样，但还是有一定相关性的。

6. 微调对数据集的分布还是比较敏感。

7. 模型根据之前的先验知识，也能够理解和做一些泛化性。

8. 还是会犯一些简单的错误。

#### 三个模型的数据集：

1. SFT数据集：13000条数据。标注人员直接根据刚才的问题集里面的问题写答案。

2. RM数据集：33000条数据。标注人员对答案进行排序。

3. RLHF数据集：31000条数据。只需要prompt集里面的问题就行，不需要标注。因为这一步的标注是RM模型来打分标注的。

OpenAI专门找了40个标注人员进行标注，需要长期交流的合同工，因为这些标注任务需要一定熟练度、对业务的理解、并需要做到随时沟通。


